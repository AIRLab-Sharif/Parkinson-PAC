{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "charged-silicon",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "colored-parker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import mne\n",
    "import json\n",
    "\n",
    "# import scipy.io as sio\n",
    "# from scipy import signal\n",
    "\n",
    "import pac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "weekly-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pac(pac, high_freq, low_freq):\n",
    "    fig = plt.figure(figsize=(7, 15))\n",
    "    ax = fig.subplots()\n",
    "    im = ax.imshow(pac, origin='lower', interpolation='nearest')\n",
    "\n",
    "    xticks_num = (low_freq[1] - low_freq[0]) / 5\n",
    "    yticks_num = (high_freq[1] - high_freq[0]) / 10\n",
    "\n",
    "    ax.xaxis.set_major_locator(mticker.MaxNLocator(5))\n",
    "    ticks_loc = ax.get_xticks()\n",
    "    ax.xaxis.set_major_locator(mticker.FixedLocator(ticks_loc))\n",
    "    xticks = [''] + [int(n) for n in np.linspace(low_freq[0],\n",
    "                                                 low_freq[1], ticks_loc.shape[0]-2).tolist()] + ['']\n",
    "    ax.set_xticklabels(xticks)\n",
    "\n",
    "    ax.yaxis.set_major_locator(mticker.MaxNLocator(10))\n",
    "    ticks_loc = ax.get_yticks()\n",
    "    ax.yaxis.set_major_locator(mticker.FixedLocator(ticks_loc))\n",
    "    yticks = [''] + [int(n) for n in np.linspace(high_freq[0],\n",
    "                                                 high_freq[1], ticks_loc.shape[0]-2).tolist()] + ['']\n",
    "    ax.set_yticklabels(yticks)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def create_elc_file(task):\n",
    "    with open(os.path.join(task.dir, task.file_formatter.format('electrodes.elc')), 'w') as elc:\n",
    "        locs = pd.read_csv(os.path.join(\n",
    "            task.dir, task.file_formatter.format('electrodes.tsv')), sep=\"\\t\")\n",
    "        locs = locs.iloc[:64]\n",
    "        locs = locs.append(pd.DataFrame([{'name': 'RPA', 'x': 0, 'y': 1, 'z': 0},\n",
    "                                  {'name': 'LPA', 'x': 0, 'y': -1, 'z': 0},\n",
    "                                  {'name': 'Nz', 'x': 1, 'y': 0, 'z': 0}, ]))\n",
    "        elc.write('\\n'.join([\n",
    "            '# ASA electrode file',\n",
    "            'ReferenceLabel\tavg',\n",
    "            'UnitPosition\tmm',\n",
    "            f'NumberPositions=\t{locs.shape[0]}',\n",
    "            'Positions',\n",
    "        ]))\n",
    "        elc.write('\\n')\n",
    "        elc.write(\n",
    "            '\\n'.join(locs.agg(lambda loc: f'{loc.x}\\t{loc.y}\\t{loc.z}', axis=1)))\n",
    "        elc.write('\\n')\n",
    "        elc.write('Labels\\n')\n",
    "        elc.write('\\n'.join(locs.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "protecting-shape",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_tasks_df(df):\n",
    "    tasks = []\n",
    "\n",
    "    for _, participant in df.iterrows():\n",
    "        if participant.Group == 'PD':\n",
    "            sessions = [(1, 1 * (participant.sess1_Med == 'ON')),\n",
    "                        (2, 1 * (participant.sess2_Med == 'ON'))]\n",
    "        else:\n",
    "            sessions = [(1, 2)]\n",
    "\n",
    "        for sess, pd_drug_type in sessions:\n",
    "            participant_tasks = {}\n",
    "            participant_tasks['participant_id'] = participant['participant_id']\n",
    "            participant_tasks['pd_drug_type'] = pd_drug_type\n",
    "            participant_tasks['isMale'] = participant['sex'] == 'Male'\n",
    "            participant_tasks['age'] = participant['age']\n",
    "            participant_tasks['dir'] = os.path.join(DS_PATH, participant['participant_id'], f'ses-{sess:02}', 'eeg',)\n",
    "            participant_tasks['file'] = f'{participant[\"participant_id\"]}_ses-{sess:02}_eeg_{participant[\"participant_id\"]}_ses-{sess:02}_task-Rest_eeg.mat'\n",
    "            participant_tasks['file_formatter'] = f'{participant[\"participant_id\"]}_ses-{sess:02}_task-Rest_{{}}'\n",
    "            participant_tasks['path'] = os.path.join(\n",
    "                participant_tasks['dir'], participant_tasks['file'])\n",
    "\n",
    "            tasks.append(participant_tasks)\n",
    "\n",
    "    tasks_df = pd.DataFrame(tasks)\n",
    "\n",
    "    return tasks_df\n",
    "\n",
    "\n",
    "def _test_tasks_df(tasks_df, i=0):\n",
    "    task = tasks_df.iloc[i]\n",
    "\n",
    "    assert os.path.exists(task.path)\n",
    "\n",
    "    ds = sio.loadmat(task.path)\n",
    "\n",
    "    ds['data'] = ds['EEG']\n",
    "\n",
    "    nbchan = ds['data'][0, 0]['nbchan'][0, 0]  # .dtype\n",
    "    Fs = ds['data'][0, 0]['srate'][0, 0]\n",
    "    times = ds['data'][0, 0]['times']\n",
    "    data = ds['data'][0, 0]['data']\n",
    "\n",
    "    dtypes = [k for k in ds['data'][0, 0]['event'].dtype.names]\n",
    "    events = pd.DataFrame([{n: event[n].item() if event[n].size > 0 else None for n in dtypes}\n",
    "                           for event in ds['data'][0, 0]['event'][0]])\n",
    "\n",
    "    electrodes = pd.read_csv(os.path.join(\n",
    "        task['dir'], task['file_formatter'].format('electrodes.tsv')), sep='\\t')\n",
    "\n",
    "    reject = ds['data'][0, 0]['reject']\n",
    "\n",
    "    print(events)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-notebook",
   "metadata": {},
   "source": [
    "# Create Task list in `tasks_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "random-blend",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_completed(task, event=None) -> bool:\n",
    "    json_path = os.path.join(task['dir'], task['file_formatter'].format('completed.json'))\n",
    "    if os.path.exists(json_path):\n",
    "        with open() as f:\n",
    "            completed = json.load(f)\n",
    "    else:\n",
    "        completed = {}\n",
    "    \n",
    "    if event is None:\n",
    "        return completed.get('total', False)\n",
    "    else:\n",
    "        return completed.get(event, False)\n",
    "\n",
    "\n",
    "def update_completed(task, event=None) -> bool:\n",
    "    json_path = os.path.join(task['dir'], task['file_formatter'].format('completed.json'))\n",
    "    if os.path.exists(json_path):\n",
    "        with open() as f:\n",
    "            completed = json.load(f)\n",
    "    else:\n",
    "        completed = {}\n",
    "\n",
    "    if event is None:\n",
    "        completed['total'] = True\n",
    "    else:\n",
    "        completed[event] = True\n",
    "\n",
    "    with open(os.path.join(json_path), 'w') as f:\n",
    "        json.dump(f, completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "written-holder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_erps(erps: dict, task=None):\n",
    "    mvls = {}\n",
    "    mvl_2ds = {}\n",
    "\n",
    "    for event_type, erp in erps.items():\n",
    "        mvl_2d = np.zeros(\n",
    "            (erp.info['nchan'], erp.info['nchan'], 200-32+1, 40-4+1))\n",
    "        mvl = np.zeros((erp.info['nchan'], erp.info['nchan'], ))\n",
    "        tfds = {}\n",
    "\n",
    "        erp_df = erp.to_data_frame()\n",
    "        erp_df = erp_df.set_index('time')\n",
    "\n",
    "        if task is not None:\n",
    "            print(f'{task.participant_id} {event_type} tfd started')\n",
    "        \n",
    "        for ch in erp_df:\n",
    "            tfd = pac.rid_rihaczek(erp_df[ch], int(erp.info['sfreq']))\n",
    "            tfds[ch] = tfd\n",
    "\n",
    "        for chx, chxname in enumerate(erp_df):\n",
    "            chy = chx\n",
    "            chyname = chxname\n",
    "            # for chy, chyname in enumerate(erp_df):\n",
    "            # print(chxname, chyname)\n",
    "\n",
    "            # todo:\n",
    "            # if(check_completed(task, f'{event_type}_{chxname}_{chyname}')):\n",
    "            #     continue\n",
    "\n",
    "            mvl_2d[chx, chy] = pac.tfMVL_tfd2_2d(\n",
    "                tfds[chxname], tfds[chyname], [32, 200], [4, 40])\n",
    "            mvl[chx, chy] = pac.tfMVL_tfd2(\n",
    "                tfds[chxname], tfds[chyname], [32, 200], [4, 40])\n",
    "            \n",
    "        mvls[event_type] = mvl\n",
    "        mvl_2ds[event_type] = mvl_2d\n",
    "\n",
    "    return mvls, mvl_2ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "assigned-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_sub(task):\n",
    "    if(check_completed(task)):\n",
    "        return\n",
    "\n",
    "    raw = mne.io.read_raw_eeglab(os.path.join(task['dir'], task['file_formatter'].format('eeg.set')),\n",
    "                                 preload=True, verbose=0)\n",
    "    raw.set_eeg_reference()\n",
    "    raw.drop_channels(['X', 'Y', 'Z'])\n",
    "\n",
    "    create_elc_file(task)\n",
    "    montage = mne.channels.read_custom_montage(os.path.join(\n",
    "        task.dir, task.file_formatter.format('electrodes.elc')))\n",
    "    raw.set_montage(montage)\n",
    "\n",
    "    eeg_picks = mne.pick_types(raw.info, eeg=True, meg=False, eog=True)\n",
    "    freqs = (60, 120, 180, 240)\n",
    "    raw_notch = raw.copy().notch_filter(freqs=freqs, picks=eeg_picks, verbose=0)\n",
    "    raw_filtered = raw_notch.copy().filter(l_freq=1, h_freq=150, verbose=0)\n",
    "\n",
    "    events, event_dict = mne.events_from_annotations(raw_filtered, verbose=0)\n",
    "    epochs = mne.Epochs(raw_filtered, events, event_id=event_dict,\n",
    "                        tmin=-0.2, tmax=1, preload=True, verbose=0)\n",
    "\n",
    "    selected_events = ['S200', 'S201', 'S202']\n",
    "    erps = {}\n",
    "    for ev in selected_events:\n",
    "        erps[ev] = epochs[ev].average()\n",
    "        \n",
    "    mvls, mvl_2ds = analyse_erps(erps, task)\n",
    "    np.savez_compressed(os.path.join(task['dir'], task['file_formatter'].format('mvls')),\n",
    "                        **mvls)\n",
    "    np.savez_compressed(os.path.join(task['dir'], task['file_formatter'].format('mvl_2ds')),\n",
    "                        **mvl_2ds)\n",
    "    update_completed(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "systematic-psychology",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-844387c5604c>:4: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(os.path.join(task['dir'], task['file_formatter'].format('eeg.set')),\n",
      "sub-001 S200 tfd completed for all channels\n",
      "Fp1 Fp1\n",
      "Fz Fz\n",
      "F3 F3\n",
      "F7 F7\n",
      "FT9 FT9\n",
      "FC5 FC5\n",
      "FC1 FC1\n",
      "C3 C3\n",
      "T7 T7\n",
      "TP9 TP9\n",
      "CP5 CP5\n",
      "CP1 CP1\n",
      "Pz Pz\n",
      "P3 P3\n",
      "P7 P7\n",
      "O1 O1\n",
      "Oz Oz\n",
      "O2 O2\n",
      "P4 P4\n",
      "P8 P8\n",
      "TP10 TP10\n",
      "CP6 CP6\n",
      "CP2 CP2\n",
      "Cz Cz\n",
      "C4 C4\n",
      "T8 T8\n",
      "FT10 FT10\n",
      "FC6 FC6\n",
      "FC2 FC2\n",
      "F4 F4\n",
      "F8 F8\n",
      "Fp2 Fp2\n",
      "AF7 AF7\n",
      "AF3 AF3\n",
      "AFz AFz\n",
      "F1 F1\n",
      "F5 F5\n",
      "FT7 FT7\n",
      "FC3 FC3\n",
      "FCz FCz\n",
      "C1 C1\n",
      "C5 C5\n",
      "TP7 TP7\n",
      "CP3 CP3\n",
      "P1 P1\n",
      "P5 P5\n",
      "PO7 PO7\n",
      "PO3 PO3\n",
      "POz POz\n",
      "PO4 PO4\n",
      "PO8 PO8\n",
      "P6 P6\n",
      "P2 P2\n",
      "CP4 CP4\n",
      "TP8 TP8\n",
      "C6 C6\n",
      "C2 C2\n",
      "FC4 FC4\n",
      "FT8 FT8\n",
      "F6 F6\n",
      "F2 F2\n",
      "AF4 AF4\n",
      "AF8 AF8\n",
      "VEOG VEOG\n",
      "sub-001 S201 tfd completed for all channels\n",
      "Fp1 Fp1\n",
      "Fz Fz\n",
      "F3 F3\n",
      "F7 F7\n",
      "FT9 FT9\n",
      "FC5 FC5\n",
      "FC1 FC1\n",
      "C3 C3\n",
      "T7 T7\n",
      "TP9 TP9\n",
      "CP5 CP5\n",
      "CP1 CP1\n",
      "Pz Pz\n",
      "P3 P3\n",
      "P7 P7\n",
      "O1 O1\n",
      "Oz Oz\n",
      "O2 O2\n",
      "P4 P4\n",
      "P8 P8\n",
      "TP10 TP10\n",
      "CP6 CP6\n",
      "CP2 CP2\n",
      "Cz Cz\n",
      "C4 C4\n",
      "T8 T8\n",
      "FT10 FT10\n",
      "FC6 FC6\n",
      "FC2 FC2\n",
      "F4 F4\n",
      "F8 F8\n",
      "Fp2 Fp2\n",
      "AF7 AF7\n",
      "AF3 AF3\n",
      "AFz AFz\n",
      "F1 F1\n",
      "F5 F5\n",
      "FT7 FT7\n",
      "FC3 FC3\n",
      "FCz FCz\n",
      "C1 C1\n",
      "C5 C5\n",
      "TP7 TP7\n",
      "CP3 CP3\n",
      "P1 P1\n",
      "P5 P5\n",
      "PO7 PO7\n",
      "PO3 PO3\n",
      "POz POz\n",
      "PO4 PO4\n",
      "PO8 PO8\n",
      "P6 P6\n",
      "P2 P2\n",
      "CP4 CP4\n",
      "TP8 TP8\n",
      "C6 C6\n",
      "C2 C2\n",
      "FC4 FC4\n",
      "FT8 FT8\n",
      "F6 F6\n",
      "F2 F2\n",
      "AF4 AF4\n",
      "AF8 AF8\n",
      "VEOG VEOG\n",
      "sub-001 S202 tfd completed for all channels\n",
      "Fp1 Fp1\n",
      "Fz Fz\n",
      "F3 F3\n",
      "F7 F7\n",
      "FT9 FT9\n",
      "FC5 FC5\n",
      "FC1 FC1\n",
      "C3 C3\n",
      "T7 T7\n",
      "TP9 TP9\n",
      "CP5 CP5\n",
      "CP1 CP1\n",
      "Pz Pz\n",
      "P3 P3\n",
      "P7 P7\n",
      "O1 O1\n",
      "Oz Oz\n",
      "O2 O2\n",
      "P4 P4\n",
      "P8 P8\n",
      "TP10 TP10\n",
      "CP6 CP6\n",
      "CP2 CP2\n",
      "Cz Cz\n",
      "C4 C4\n",
      "T8 T8\n",
      "FT10 FT10\n",
      "FC6 FC6\n",
      "FC2 FC2\n",
      "F4 F4\n",
      "F8 F8\n",
      "Fp2 Fp2\n",
      "AF7 AF7\n",
      "AF3 AF3\n",
      "AFz AFz\n",
      "F1 F1\n",
      "F5 F5\n",
      "FT7 FT7\n",
      "FC3 FC3\n",
      "FCz FCz\n",
      "C1 C1\n",
      "C5 C5\n",
      "TP7 TP7\n",
      "CP3 CP3\n",
      "P1 P1\n",
      "P5 P5\n",
      "PO7 PO7\n",
      "PO3 PO3\n",
      "POz POz\n",
      "PO4 PO4\n",
      "PO8 PO8\n",
      "P6 P6\n",
      "P2 P2\n",
      "CP4 CP4\n",
      "TP8 TP8\n",
      "C6 C6\n",
      "C2 C2\n",
      "FC4 FC4\n",
      "FT8 FT8\n",
      "F6 F6\n",
      "F2 F2\n",
      "AF4 AF4\n",
      "AF8 AF8\n",
      "VEOG VEOG\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    BASE_PATH = os.path.dirname(os.path.abspath(''))\n",
    "    # DS_PATH = os.path.join(BASE_PATH, 'ds')\n",
    "    DS_PATH = os.path.join('/', 'Volumes', 'USB STICK', 'ds003490-download')\n",
    "\n",
    "    df = pd.read_csv(os.path.join(DS_PATH, 'participants.tsv'), sep=\"\\t\")\n",
    "\n",
    "    tasks_df = create_tasks_df(df)\n",
    "\n",
    "    # __test__ = 1\n",
    "    if '__test__' in locals():\n",
    "        _test_tasks_df(tasks_df, 0)\n",
    "\n",
    "    # analyse_sub(tasks_df.iloc[0])\n",
    "\n",
    "    from multiprocessing import Pool\n",
    "    with Pool(4) as p:\n",
    "        p.map(analyse_sub, tasks_df.iloc[4:])\n",
    "\n",
    "#     for task in tasks_df.iloc:\n",
    "#         analyse_task(task)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
