{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import mne\n",
    "import json\n",
    "\n",
    "# import scipy.io as sio\n",
    "# from scipy import signal\n",
    "\n",
    "import pac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pac(pac, high_freq, low_freq):\n",
    "    fig = plt.figure(figsize=(7, 15))\n",
    "    ax = fig.subplots()\n",
    "    im = ax.imshow(pac, origin='lower', interpolation='nearest')\n",
    "\n",
    "    xticks_num = (low_freq[1] - low_freq[0]) / 5\n",
    "    yticks_num = (high_freq[1] - high_freq[0]) / 10\n",
    "\n",
    "    ax.xaxis.set_major_locator(mticker.MaxNLocator(5))\n",
    "    ticks_loc = ax.get_xticks()\n",
    "    ax.xaxis.set_major_locator(mticker.FixedLocator(ticks_loc))\n",
    "    xticks = [''] + [int(n) for n in np.linspace(low_freq[0],\n",
    "                                                 low_freq[1], ticks_loc.shape[0]-2).tolist()] + ['']\n",
    "    ax.set_xticklabels(xticks)\n",
    "\n",
    "    ax.yaxis.set_major_locator(mticker.MaxNLocator(10))\n",
    "    ticks_loc = ax.get_yticks()\n",
    "    ax.yaxis.set_major_locator(mticker.FixedLocator(ticks_loc))\n",
    "    yticks = [''] + [int(n) for n in np.linspace(high_freq[0],\n",
    "                                                 high_freq[1], ticks_loc.shape[0]-2).tolist()] + ['']\n",
    "    ax.set_yticklabels(yticks)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def create_elc_file(task):\n",
    "    with open(os.path.join(task.dir, task.file_formatter.format('electrodes.elc')), 'w') as elc:\n",
    "        locs = pd.read_csv(os.path.join(\n",
    "            task.dir, task.file_formatter.format('electrodes.tsv')), sep=\"\\t\")\n",
    "        locs = locs.iloc[:64]\n",
    "        locs = locs.append(pd.DataFrame([{'name': 'RPA', 'x': 0, 'y': 1, 'z': 0},\n",
    "                                  {'name': 'LPA', 'x': 0, 'y': -1, 'z': 0},\n",
    "                                  {'name': 'Nz', 'x': 1, 'y': 0, 'z': 0}, ]))\n",
    "        elc.write('\\n'.join([\n",
    "            '# ASA electrode file',\n",
    "            'ReferenceLabel\tavg',\n",
    "            'UnitPosition\tmm',\n",
    "            f'NumberPositions=\t{locs.shape[0]}',\n",
    "            'Positions',\n",
    "        ]))\n",
    "        elc.write('\\n')\n",
    "        elc.write(\n",
    "            '\\n'.join(locs.agg(lambda loc: f'{loc.x}\\t{loc.y}\\t{loc.z}', axis=1)))\n",
    "        elc.write('\\n')\n",
    "        elc.write('Labels\\n')\n",
    "        elc.write('\\n'.join(locs.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_tasks_df(df):\n",
    "    tasks = []\n",
    "\n",
    "    for _, participant in df.iterrows():\n",
    "        if participant.Group == 'PD':\n",
    "            sessions = [(1, 1 * (participant.sess1_Med == 'ON')),\n",
    "                        (2, 1 * (participant.sess2_Med == 'ON'))]\n",
    "        else:\n",
    "            sessions = [(1, 2)]\n",
    "\n",
    "        for sess, pd_drug_type in sessions:\n",
    "            participant_tasks = {}\n",
    "            participant_tasks['participant_id'] = participant['participant_id']\n",
    "            participant_tasks['pd_drug_type'] = pd_drug_type\n",
    "            participant_tasks['isMale'] = participant['sex'] == 'Male'\n",
    "            participant_tasks['age'] = participant['age']\n",
    "            participant_tasks['dir'] = os.path.join(DS_PATH, participant['participant_id'], f'ses-{sess:02}', 'eeg',)\n",
    "            participant_tasks['file'] = f'{participant[\"participant_id\"]}_ses-{sess:02}_eeg_{participant[\"participant_id\"]}_ses-{sess:02}_task-Rest_eeg.mat'\n",
    "            participant_tasks['file_formatter'] = f'{participant[\"participant_id\"]}_ses-{sess:02}_task-Rest_{{}}'\n",
    "            participant_tasks['path'] = os.path.join(\n",
    "                participant_tasks['dir'], participant_tasks['file'])\n",
    "\n",
    "            tasks.append(participant_tasks)\n",
    "\n",
    "    tasks_df = pd.DataFrame(tasks)\n",
    "\n",
    "    return tasks_df\n",
    "\n",
    "\n",
    "def _test_tasks_df(tasks_df, i=0):\n",
    "    task = tasks_df.iloc[i]\n",
    "\n",
    "    assert os.path.exists(task.path)\n",
    "\n",
    "    ds = sio.loadmat(task.path)\n",
    "\n",
    "    ds['data'] = ds['EEG']\n",
    "\n",
    "    nbchan = ds['data'][0, 0]['nbchan'][0, 0]  # .dtype\n",
    "    Fs = ds['data'][0, 0]['srate'][0, 0]\n",
    "    times = ds['data'][0, 0]['times']\n",
    "    data = ds['data'][0, 0]['data']\n",
    "\n",
    "    dtypes = [k for k in ds['data'][0, 0]['event'].dtype.names]\n",
    "    events = pd.DataFrame([{n: event[n].item() if event[n].size > 0 else None for n in dtypes}\n",
    "                           for event in ds['data'][0, 0]['event'][0]])\n",
    "\n",
    "    electrodes = pd.read_csv(os.path.join(\n",
    "        task['dir'], task['file_formatter'].format('electrodes.tsv')), sep='\\t')\n",
    "\n",
    "    reject = ds['data'][0, 0]['reject']\n",
    "\n",
    "    print(events)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Task list in `tasks_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_completed(task, event=None) -> bool:\n",
    "    json_path = os.path.join(task['dir'], task['file_formatter'].format('completed.json'))\n",
    "    completed = {}\n",
    "    if os.path.exists(json_path):\n",
    "        with open(json_path) as f:\n",
    "            completed = json.load(f)\n",
    "    \n",
    "    if event is None:\n",
    "        return completed.get('total', False)\n",
    "    else:\n",
    "        return completed.get(event, False)\n",
    "\n",
    "\n",
    "def update_completed(task, event=None) -> bool:\n",
    "    json_path = os.path.join(task['dir'], task['file_formatter'].format('completed.json'))\n",
    "    completed = {}\n",
    "    if os.path.exists(json_path):\n",
    "        with open(json_path) as f:\n",
    "            completed = json.load(f)\n",
    "\n",
    "    if event is None:\n",
    "        completed['total'] = True\n",
    "    else:\n",
    "        completed[event] = True\n",
    "        \n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(completed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_erps(erps: dict, task=None):\n",
    "    mvls = {}\n",
    "    mvl_2ds = {}\n",
    "\n",
    "    for event_type, erp in erps.items():\n",
    "        mvl_2d = np.zeros(\n",
    "            (erp.info['nchan'], erp.info['nchan'], 200-32+1, 40-4+1))\n",
    "        mvl = np.zeros((erp.info['nchan'], erp.info['nchan'], ))\n",
    "        tfds = {}\n",
    "\n",
    "        erp_df = erp.to_data_frame()\n",
    "        erp_df = erp_df.set_index('time')\n",
    "\n",
    "        if task is not None:\n",
    "            print(f'{task.participant_id} {event_type} tfd started')\n",
    "        \n",
    "        for ch in erp_df:\n",
    "            tfd = pac.rid_rihaczek(erp_df[ch], int(erp.info['sfreq']))\n",
    "            tfds[ch] = tfd\n",
    "\n",
    "        for chx, chxname in enumerate(erp_df):\n",
    "            chy = chx\n",
    "            chyname = chxname\n",
    "            # for chy, chyname in enumerate(erp_df):\n",
    "            # print(chxname, chyname)\n",
    "\n",
    "            # todo:\n",
    "            # if(check_completed(task, f'{event_type}_{chxname}_{chyname}')):\n",
    "            #     continue\n",
    "\n",
    "            mvl_2d[chx, chy] = pac.tfMVL_tfd2_2d(\n",
    "                tfds[chxname], tfds[chyname], [32, 200], [4, 40])\n",
    "            mvl[chx, chy] = pac.tfMVL_tfd2(\n",
    "                tfds[chxname], tfds[chyname], [32, 200], [4, 40])\n",
    "            \n",
    "        mvls[event_type] = mvl\n",
    "        mvl_2ds[event_type] = mvl_2d\n",
    "\n",
    "    return mvls, mvl_2ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_sub(task):\n",
    "    if(check_completed(task)):\n",
    "        return\n",
    "\n",
    "    raw = mne.io.read_raw_eeglab(os.path.join(task['dir'], task['file_formatter'].format('eeg.set')),\n",
    "                                 preload=True, verbose=0)\n",
    "    raw.set_eeg_reference()\n",
    "    raw.drop_channels(['X', 'Y', 'Z'])\n",
    "\n",
    "    create_elc_file(task)\n",
    "    montage = mne.channels.read_custom_montage(os.path.join(\n",
    "        task.dir, task.file_formatter.format('electrodes.elc')))\n",
    "    raw.set_montage(montage)\n",
    "\n",
    "    eeg_picks = mne.pick_types(raw.info, eeg=True, meg=False, eog=True)\n",
    "    freqs = (60, 120, 180, 240)\n",
    "    raw_notch = raw.copy().notch_filter(freqs=freqs, picks=eeg_picks, verbose=0)\n",
    "    raw_filtered = raw_notch.copy().filter(l_freq=1, h_freq=150, verbose=0)\n",
    "\n",
    "    events, event_dict = mne.events_from_annotations(raw_filtered, verbose=0)\n",
    "    epochs = mne.Epochs(raw_filtered, events, event_id=event_dict,\n",
    "                        tmin=-0.2, tmax=1, preload=True, verbose=0)\n",
    "\n",
    "    selected_events = ['S200', 'S201', 'S202']\n",
    "    erps = {}\n",
    "    for ev in selected_events:\n",
    "        erps[ev] = epochs[ev].average()\n",
    "        \n",
    "    mvls, mvl_2ds = analyse_erps(erps, task)\n",
    "    np.savez_compressed(os.path.join(task['dir'], task['file_formatter'].format('mvls')),\n",
    "                        **mvls)\n",
    "    np.savez_compressed(os.path.join(task['dir'], task['file_formatter'].format('mvl_2ds')),\n",
    "                        **mvl_2ds)\n",
    "    update_completed(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-2:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-865bec413e38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mmultiprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalyse_sub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#     for task in tasks_df.iloc:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\r\n",
    "    # BASE_PATH = os.path.join(os.getenv('HOME'), 'DS') \r\n",
    "    # DS_PATH = os.path.join(BASE_PATH, 'ds003490-download')\r\n",
    "    BASE_PATH = 'G:\\\\filmuniversity\\\\Master sharif\\\\MasterProject\\\\data'\r\n",
    "    DS_PATH = 'G:\\\\filmuniversity\\\\Master sharif\\\\MasterProject\\\\data\\\\parkinsons-oddball'\r\n",
    "\r\n",
    "    df = pd.read_csv(os.path.join(DS_PATH, 'participants.tsv'), sep=\"\\t\")\r\n",
    "\r\n",
    "    tasks_df = create_tasks_df(df)\r\n",
    "\r\n",
    "    # __test__ = 1\r\n",
    "    if '__test__' in locals():\r\n",
    "        _test_tasks_df(tasks_df, 0)\r\n",
    "\r\n",
    "    # analyse_sub(tasks_df.iloc[0])\r\n",
    "\r\n",
    "    # from multiprocessing import Pool\r\n",
    "    # with Pool(4) as p:\r\n",
    "    #     p.map(analyse_sub, tasks_df.iloc[4:])\r\n",
    "\r\n",
    "    for task in tasks_df.iloc:\r\n",
    "        analyse_task(task)\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}