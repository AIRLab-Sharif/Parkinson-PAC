{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pac\n",
    "\n",
    "\n",
    "\n",
    "suffix = '_1_200_double'\n",
    "gamma = [1, 200]\n",
    "beta = [1, 50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     37
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def create_tasks_df(ds_path=None):\n",
    "    if ds_path is None:\n",
    "        with open('config.json') as f:\n",
    "            config = json.load(f)\n",
    "        base_path = config['BASE_PATH']\n",
    "        ds_path = os.path.join(base_path, 'ds003490-download')\n",
    "\n",
    "    df = pd.read_csv(os.path.join(ds_path, 'participants.tsv'), sep=\"\\t\")\n",
    "    tasks = []\n",
    "\n",
    "    for _, participant in df.iterrows():\n",
    "        if participant.Group == 'PD':\n",
    "            sessions = [(1, 1 * (participant.sess1_Med == 'ON')),\n",
    "                        (2, 1 * (participant.sess2_Med == 'ON'))]\n",
    "        else:\n",
    "            sessions = [(1, 2)]\n",
    "\n",
    "        for sess, pd_drug_type in sessions:\n",
    "            participant_tasks = {}\n",
    "            participant_tasks['participant_id'] = participant['participant_id']\n",
    "            participant_tasks['pd_drug_type'] = pd_drug_type\n",
    "            participant_tasks['isMale'] = participant['sex'] == 'Male'\n",
    "            participant_tasks['age'] = participant['age']\n",
    "            participant_tasks['dir'] = os.path.join(ds_path, participant['participant_id'], f'ses-{sess:02}', 'eeg', )\n",
    "            participant_tasks[\n",
    "                'file'] = f'{participant[\"participant_id\"]}_ses-{sess:02}_eeg_{participant[\"participant_id\"]}_ses-{sess:02}_task-Rest_eeg.mat'\n",
    "            participant_tasks['file_formatter'] = f'{participant[\"participant_id\"]}_ses-{sess:02}_task-Rest_{{}}'\n",
    "            participant_tasks['path'] = os.path.join(\n",
    "                participant_tasks['dir'], participant_tasks['file'])\n",
    "\n",
    "            tasks.append(participant_tasks)\n",
    "\n",
    "    tasks_df = pd.DataFrame(tasks)\n",
    "\n",
    "    return tasks_df\n",
    "\n",
    "\n",
    "def _test_tasks_df(tasks_df, i=0):\n",
    "    task = tasks_df.iloc[i]\n",
    "\n",
    "    assert os.path.exists(task.path)\n",
    "\n",
    "    ds = sio.loadmat(task.path)\n",
    "\n",
    "    ds['data'] = ds['EEG']\n",
    "\n",
    "    nbchan = ds['data'][0, 0]['nbchan'][0, 0]  # .dtype\n",
    "    Fs = ds['data'][0, 0]['srate'][0, 0]\n",
    "    times = ds['data'][0, 0]['times']\n",
    "    data = ds['data'][0, 0]['data']\n",
    "\n",
    "    dtypes = [k for k in ds['data'][0, 0]['event'].dtype.names]\n",
    "    events = pd.DataFrame([{n: event[n].item() if event[n].size > 0 else None for n in dtypes}\n",
    "                           for event in ds['data'][0, 0]['event'][0]])\n",
    "\n",
    "    electrodes = pd.read_csv(os.path.join(\n",
    "        task['dir'], task['file_formatter'].format('electrodes.tsv')), sep='\\t')\n",
    "\n",
    "    reject = ds['data'][0, 0]['reject']\n",
    "\n",
    "    print(events)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Task list in `tasks_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0,
     13
    ]
   },
   "outputs": [],
   "source": [
    "def check_completed(task, event=None) -> bool:\n",
    "    json_path = os.path.join(task['dir'], task['file_formatter'].format(f'completed{suffix}.json'))\n",
    "    completed = {}\n",
    "    if os.path.exists(json_path):\n",
    "        with open(json_path) as f:\n",
    "            completed = json.load(f)\n",
    "    \n",
    "    if event is None:\n",
    "        return completed.get('total', False)\n",
    "    else:\n",
    "        return completed.get(event, False)\n",
    "\n",
    "\n",
    "def update_completed(task, event=None) -> bool:\n",
    "    json_path = os.path.join(task['dir'], task['file_formatter'].format(f'completed{suffix}.json'))\n",
    "    completed = {}\n",
    "    if os.path.exists(json_path):\n",
    "        with open(json_path) as f:\n",
    "            completed = json.load(f)\n",
    "\n",
    "    if event is None:\n",
    "        completed['total'] = True\n",
    "    else:\n",
    "        completed[event] = True\n",
    "        \n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(completed, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def analyse_erps(erps: dict, task=None):\n",
    "    mvls = {}\n",
    "    mvl_2ds = {}\n",
    "    mvl_2d_times = {}\n",
    "    \n",
    "    steps = list(range(-200, 1000 + 1, 200))\n",
    "    \n",
    "    groups = ['PD Med Off', 'PD Med On', 'CTL']\n",
    "\n",
    "    for event_type, erp in erps.items():\n",
    "        mvl_2d = np.zeros(\n",
    "            (erp.info['nchan'], erp.info['nchan'], gamma[1] - gamma[0] + 1, beta[1] - beta[0] + 1))\n",
    "        mvl_2d_time = np.zeros((erp.info['nchan'], gamma[1] - gamma[0] + 1, \n",
    "                                beta[1] - beta[0] + 1, len(steps) - 1 ))\n",
    "\n",
    "        mvl = np.zeros((erp.info['nchan'], erp.info['nchan'],))\n",
    "        tfds = {}\n",
    "\n",
    "        erp_df = erp.to_data_frame()\n",
    "        erp_df = erp_df.set_index('time')\n",
    "\n",
    "        if task is not None:\n",
    "            print(f'{task.participant_id} {groups[task.pd_drug_type]:10} {event_type} tfd started')\n",
    "\n",
    "        for ch in erp_df:\n",
    "            tfd = pac.rid_rihaczek(erp_df[ch], int(erp.info['sfreq']))\n",
    "            tfds[ch] = tfd\n",
    "\n",
    "        for chx, chxname in enumerate(erp_df):\n",
    "            chy = chx\n",
    "            chyname = chxname\n",
    "            \n",
    "            for i, ts in enumerate(zip(steps[:-1], steps[1:])):\n",
    "                tstart, tend = ts\n",
    "                ind_start = np.where(erp_df.index == tstart)[0][0]\n",
    "                ind_end   = np.where(erp_df.index == tend)[0][0]\n",
    "                mvl_2d_time[chx, :, :, i] = pac.tfMVL_tfd2_2d_time(\n",
    "                    tfds[chxname], tfds[chxname], gamma, beta, ind_start, ind_end)\n",
    "\n",
    "            \n",
    "            for chy, chyname in enumerate(erp_df):\n",
    "                # todo:\n",
    "                # if(check_completed(task, f'{event_type}_{chxname}_{chyname}')):\n",
    "                #     continue\n",
    "\n",
    "                mvl_2d[chx, chy] = pac.tfMVL_tfd2_2d(\n",
    "                    tfds[chxname], tfds[chyname], gamma, beta)\n",
    "                mvl[chx, chy] = mvl_2d[chx, chy].sum()\n",
    "            # mvl[chx, chy] = pac.tfMVL_tfd2(\n",
    "            #     tfds[chxname], tfds[chyname], gamma, beta)\n",
    "\n",
    "        mvls[event_type] = mvl\n",
    "        mvl_2ds[event_type] = mvl_2d\n",
    "        mvl_2d_times[event_type] = mvl_2d_time\n",
    "\n",
    "    return mvls, mvl_2ds, mvl_2d_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def analyse_sub(task):\n",
    "    if (check_completed(task)):\n",
    "        return\n",
    "\n",
    "    raw = mne.io.read_raw_eeglab(os.path.join(task['dir'], 'pre_' + task['file_formatter'].format('eeg_double.set')),\n",
    "                                 preload=True, verbose=0)\n",
    "    # raw.drop_channels(['X', 'Y', 'Z'])\n",
    "    raw.drop_channels(['VEOG'])\n",
    "    raw.set_eeg_reference()\n",
    "    \n",
    "    for ch in raw._data:\n",
    "        ch -= ch.mean()\n",
    "        ch /= ch.std()\n",
    "\n",
    "    # create_elc_file(task)\n",
    "    # montage = mne.channels.read_custom_montage(os.path.join(\n",
    "    #     task.dir, task.file_formatter.format('electrodes.elc')))\n",
    "    montage = mne.channels.read_custom_montage('Standard-10-20-Cap81.locs')\n",
    "    raw.set_montage(montage)\n",
    "\n",
    "    # mne.viz.plot_topomap(raw._data[:, 194000], raw.info, axes=ax,\n",
    "    #                      show=False)\n",
    "\n",
    "    # eeg_picks = mne.pick_types(raw.info, eeg=True, meg=False, eog=True)\n",
    "    # freqs = (60, 120, 180, 240)\n",
    "    # raw_notch = raw.copy().notch_filter(freqs=freqs, picks=eeg_picks, verbose=0)\n",
    "    # raw_filtered = raw_notch.copy().filter(l_freq=1, h_freq=150, verbose=0)\n",
    "    \n",
    "    events, event_dict = mne.events_from_annotations(raw, verbose=0)\n",
    "\n",
    "    selected_events = ['S200', 'S201', 'S202']\n",
    "    event_types = {'S200': 'Target', 'S201': 'Standard', 'S202': 'Novelty'}\n",
    "    kwargs = {'S200': {'baseline': (0.250, 0.450), 'tmin': 0.250, 'tmax':1.450},\n",
    "              'S201': {'baseline': (0.250, 0.450), 'tmin': 0.250, 'tmax':1.450},\n",
    "              'S202': {'baseline': (-.200,     0), 'tmin': -.200, 'tmax':1.000},}\n",
    "\n",
    "    erps = {}\n",
    "    epochs_data = {}\n",
    "    for ev in selected_events:\n",
    "        epochs = mne.Epochs(raw, events[events[:, 2] == event_dict[ev]],\n",
    "                            event_id={ev: event_dict[ev]}, preload=True, verbose=0, **(kwargs[ev]))\n",
    "        erps[ev] = epochs[ev].average()\n",
    "        epochs_data[ev] = epochs[ev]._data\n",
    "        \n",
    "        \n",
    "    np.savez_compressed(os.path.join(task['dir'], task['file_formatter'].format(f'epochs')),\n",
    "                        **epochs_data)\n",
    "    \n",
    "    np.savez_compressed(os.path.join(task['dir'], task['file_formatter'].format(f'erps')),\n",
    "                        **erps)\n",
    "    \n",
    "#     return\n",
    "\n",
    "    mvls, mvl_2ds, mvl_2d_times = analyse_erps(erps, task)\n",
    "    np.savez_compressed(os.path.join(task['dir'], task['file_formatter'].format(f'mvls{suffix}')),\n",
    "                        **mvls)\n",
    "    np.savez_compressed(os.path.join(task['dir'], task['file_formatter'].format(f'mvl_2ds{suffix}')),\n",
    "                        **mvl_2ds)\n",
    "    np.savez_compressed(os.path.join(task['dir'], task['file_formatter'].format(f'mvl_2d_times{suffix}')),\n",
    "                        **mvl_2d_times)\n",
    "    update_completed(task)\n",
    "    print(f'{task.participant_id} completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_erps2(erps: dict, task=None):\n",
    "    mvl_cross_times = {}\n",
    "    \n",
    "    steps = list(range(-200, 1000 + 1, 200))\n",
    "    \n",
    "    groups = ['PD Med Off', 'PD Med On', 'CTL']\n",
    "    \n",
    "    selected_channels = ['FC3','FC4','AF3','AF4','F3','F4','Fz','Pz','Cz','FCz']\n",
    "    selected_channels_index = [38, 57, 33, 61, 2, 29, 1, 12, 23, 39]\n",
    "    \n",
    "#     print(erps.items())\n",
    "\n",
    "    for event_type, erp in erps.items():\n",
    "        mvl_cross_time = np.zeros((10, 10, gamma[1] - gamma[0] + 1, \n",
    "                                beta[1] - beta[0] + 1, len(steps) - 1 ))\n",
    "\n",
    "        tfds_time = {}\n",
    "\n",
    "        erp_df = erp.to_data_frame()\n",
    "        erp_df.time = list(range(-200, 1000 + 1, 2))\n",
    "        erp_df = erp_df.set_index('time')\n",
    "\n",
    "        if task is not None:\n",
    "            print(f'{task.participant_id} {groups[task.pd_drug_type]:10} {event_type} tfd started')\n",
    "\n",
    "        for ch in selected_channels: #todo\n",
    "            tfd_time = []\n",
    "\n",
    "            for i, ts in enumerate(zip(steps[:-1], steps[1:])):\n",
    "                tstart, tend = ts\n",
    "#                 print(tstart, tend, min(erp_df.index), max(erp_df.index))\n",
    "                ind_start = np.where(erp_df.index == tstart)[0][0]\n",
    "                ind_end = np.where(erp_df.index == tend)[0][0]\n",
    "                tfd_time.append(pac.rid_rihaczek(\n",
    "                    erp_df[ch][ind_start:ind_end], int(erp.info['sfreq'])))\n",
    "            tfds_time[ch] = tfd_time\n",
    "\n",
    "        # for ch in erp_df: #todo\n",
    "        #     tfd = pac.rid_rihaczek(erp_df[ch], int(erp.info['sfreq']))\n",
    "        #     tfds[ch] = tfd\n",
    "\n",
    "        for chx, chxname in enumerate(selected_channels):\n",
    "            for chy, chyname in enumerate(selected_channels):\n",
    "                for i, ts in enumerate(zip(steps[:-1], steps[1:])):\n",
    "                    tstart, tend = ts\n",
    "                    ind_start = np.where(erp_df.index == tstart)[0][0]\n",
    "                    ind_end   = np.where(erp_df.index == tend)[0][0]\n",
    "                    # print('check')\n",
    "                    mvl_cross_time[chx, chy, :, :, i] = pac.tfMVL_tfd2_2d_time(\n",
    "                        tfds_time[chxname][i], tfds_time[chyname][i], gamma, beta, ind_start, ind_end)\n",
    "\n",
    "        mvl_cross_times[event_type] = mvl_cross_time\n",
    "\n",
    "    return mvl_cross_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_sub2(task):\n",
    "    raw = mne.io.read_raw_eeglab(os.path.join(task['dir'], 'pre_' + task['file_formatter'].format('eeg_double.set')),\n",
    "                                 preload=True, verbose=0)\n",
    "    # raw.drop_channels(['X', 'Y', 'Z'])\n",
    "    # raw.drop_channels(['VEOG'])\n",
    "    # raw.set_eeg_reference()\n",
    "\n",
    "    for ch in raw._data:\n",
    "        ch -= ch.mean()\n",
    "        ch /= ch.std()\n",
    "\n",
    "    # create_elc_file(task)\n",
    "    # montage = mne.channels.read_custom_montage(os.path.join(\n",
    "    #     task.dir, task.file_formatter.format('electrodes.elc')))\n",
    "    montage = mne.channels.read_custom_montage('Standard-10-20-Cap81.locs')\n",
    "    raw.set_montage(montage)\n",
    "\n",
    "    # mne.viz.plot_topomap(raw._data[:, 194000], raw.info, axes=ax,\n",
    "    #                      show=False)\n",
    "\n",
    "    # eeg_picks = mne.pick_types(raw.info, eeg=True, meg=False, eog=True)\n",
    "    # freqs = (60, 120, 180, 240)\n",
    "    # raw_notch = raw.copy().notch_filter(freqs=freqs, picks=eeg_picks, verbose=0)\n",
    "    # raw_filtered = raw_notch.copy().filter(l_freq=1, h_freq=150, verbose=0)\n",
    "    \n",
    "    events, event_dict = mne.events_from_annotations(raw, verbose=0)\n",
    "\n",
    "    selected_events = ['S200', 'S201', 'S202']\n",
    "    event_types = {'S200': 'Target', 'S201': 'Standard', 'S202': 'Novelty'}\n",
    "    kwargs = {'S200': {'baseline': (0.250, 0.450), 'tmin': 0.250, 'tmax':1.450},\n",
    "              'S201': {'baseline': (0.250, 0.450), 'tmin': 0.250, 'tmax':1.450},\n",
    "              'S202': {'baseline': (-.200,     0), 'tmin': -.200, 'tmax':1.000},}\n",
    "\n",
    "    erps = {}\n",
    "    epochs_data = {}\n",
    "    for ev in selected_events:\n",
    "        epochs = mne.Epochs(raw, events[events[:, 2] == event_dict[ev]],\n",
    "                            event_id={ev: event_dict[ev]}, preload=True, verbose=0, **(kwargs[ev]))\n",
    "        erps[ev] = epochs[ev].average()\n",
    "        epochs_data[ev] = epochs[ev]._data\n",
    "        \n",
    "        \n",
    "    mvl_cross_times = analyse_erps2(erps, task)\n",
    "    np.savez_compressed(os.path.join(task['dir'], task['file_formatter'].format(f'mvl_cross_times{suffix}')),\n",
    "                        **mvl_cross_times)\n",
    "    update_completed(task)\n",
    "    print(f'{task.participant_id} completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-21f79a9a1a20>:3: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  preload=True, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-001 PD Med On  S200 tfd started\n",
      "sub-001 PD Med On  S201 tfd started\n",
      "sub-001 PD Med On  S202 tfd started\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    tasks_df = create_tasks_df()\n",
    "\n",
    "#     analyse_sub(tasks_df.iloc[0])\n",
    "\n",
    "#     from multiprocessing import Pool\n",
    "#     with Pool(4) as p:\n",
    "#         p.map(analyse_sub2, tasks_df.iloc)\n",
    "\n",
    "    for task in tasks_df.iloc:\n",
    "        analyse_sub2(task)\n",
    "    print('finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-fb3408f77963>:7: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  preload=True, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "task = tasks_df.iloc[0]\n",
    "if 1:\n",
    "    if (check_completed(task)):\n",
    "        pass\n",
    "    \n",
    "    raw = mne.io.read_raw_eeglab(os.path.join(task['dir'], 'pre_' + task['file_formatter'].format('eeg_double.set')),\n",
    "                                 preload=True, verbose=0)\n",
    "    # raw.drop_channels(['X', 'Y', 'Z'])\n",
    "#     raw.drop_channels(['VEOG'])\n",
    "#     raw.set_eeg_reference()\n",
    "    \n",
    "#     for ch in raw._data:\n",
    "#         ch -= ch.mean()\n",
    "#         ch /= ch.std()\n",
    "\n",
    "    # create_elc_file(task)\n",
    "    # montage = mne.channels.read_custom_montage(os.path.join(\n",
    "    #     task.dir, task.file_formatter.format('electrodes.elc')))\n",
    "    montage = mne.channels.read_custom_montage('Standard-10-20-Cap81.locs')\n",
    "    raw.set_montage(montage)\n",
    "\n",
    "    # mne.viz.plot_topomap(raw._data[:, 194000], raw.info, axes=ax,\n",
    "    #                      show=False)\n",
    "\n",
    "    # eeg_picks = mne.pick_types(raw.info, eeg=True, meg=False, eog=True)\n",
    "    # freqs = (60, 120, 180, 240)\n",
    "    # raw_notch = raw.copy().notch_filter(freqs=freqs, picks=eeg_picks, verbose=0)\n",
    "    # raw_filtered = raw_notch.copy().filter(l_freq=1, h_freq=150, verbose=0)\n",
    "    \n",
    "    events, event_dict = mne.events_from_annotations(raw, verbose=0)\n",
    "\n",
    "    selected_events = ['S200', 'S201', 'S202']\n",
    "    event_types = {'S200': 'Target', 'S201': 'Standard', 'S202': 'Novelty'}\n",
    "    kwargs = {'S200': {'baseline': (0.250, 0.450), 'tmin': 0.250, 'tmax':1.450},\n",
    "              'S201': {'baseline': (0.250, 0.450), 'tmin': 0.250, 'tmax':1.450},\n",
    "              'S202': {'baseline': (-.200,     0), 'tmin': -.200, 'tmax':1.000},}\n",
    "\n",
    "    erps = {}\n",
    "    epochs_data = {}\n",
    "    for ev in selected_events:\n",
    "        epochs = mne.Epochs(raw, events[events[:, 2] == event_dict[ev]],\n",
    "                            event_id={ev: event_dict[ev]}, preload=True, verbose=0, **(kwargs[ev]))\n",
    "        erps[ev] = epochs[ev].average()\n",
    "        epochs_data[ev] = epochs[ev]._data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    mvls = {}\n",
    "    mvl_2ds = {}\n",
    "    mvl_2d_times = {}\n",
    "    \n",
    "    steps = list(range(-200, 1000 + 1, 200))\n",
    "    \n",
    "    groups = ['PD Med Off', 'PD Med On', 'CTL']\n",
    "\n",
    "    for event_type, erp in erps.items():\n",
    "        mvl_2d = np.zeros(\n",
    "            (erp.info['nchan'], erp.info['nchan'], gamma[1] - gamma[0] + 1, beta[1] - beta[0] + 1))\n",
    "        mvl_2d_time = np.zeros((erp.info['nchan'], gamma[1] - gamma[0] + 1, \n",
    "                                beta[1] - beta[0] + 1, len(steps) - 1 ))\n",
    "\n",
    "        mvl = np.zeros((erp.info['nchan'], erp.info['nchan'],))\n",
    "        tfds = {}\n",
    "\n",
    "        erp_df = erp.to_data_frame()\n",
    "        erp_df.time = list(range(-200, 1000 + 1, 2))\n",
    "        erp_df = erp_df.set_index('time')\n",
    "\n",
    "        if task is not None:\n",
    "            print(f'{task.participant_id} {groups[task.pd_drug_type]:10} {event_type} tfd started')\n",
    "\n",
    "        for ch in erp_df:\n",
    "            tfd = pac.rid_rihaczek(erp_df[ch], int(erp.info['sfreq']))\n",
    "            tfds[ch] = tfd\n",
    "\n",
    "        for chx, chxname in enumerate(erp_df):\n",
    "            chy = chx\n",
    "            chyname = chxname\n",
    "            \n",
    "            for i, ts in enumerate(zip(steps[:-1], steps[1:])):\n",
    "                tstart, tend = ts\n",
    "                ind_start = np.where(erp_df.index == tstart)[0][0]\n",
    "                ind_end   = np.where(erp_df.index == tend)[0][0]\n",
    "                mvl_2d_time[chx, :, :, i] = pac.tfMVL_tfd2_2d_time(\n",
    "                    tfds[chxname], tfds[chxname], gamma, beta, ind_start, ind_end)\n",
    "\n",
    "            \n",
    "            for chy, chyname in enumerate(erp_df):\n",
    "                # todo:\n",
    "                # if(check_completed(task, f'{event_type}_{chxname}_{chyname}')):\n",
    "                #     continue\n",
    "\n",
    "                mvl_2d[chx, chy] = pac.tfMVL_tfd2_2d(\n",
    "                    tfds[chxname], tfds[chyname], gamma, beta)\n",
    "                mvl[chx, chy] = mvl_2d[chx, chy].sum()\n",
    "            # mvl[chx, chy] = pac.tfMVL_tfd2(\n",
    "            #     tfds[chxname], tfds[chyname], gamma, beta)\n",
    "\n",
    "        mvls[event_type] = mvl\n",
    "        mvl_2ds[event_type] = mvl_2d\n",
    "        mvl_2d_times[event_type] = mvl_2d_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erp = epochs_data['S201'].mean(axis=0)[10, :]\n",
    "plt.plot(erp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('/home/kiani/DS/ds003490-download/extracted_data/mvls30_6_sub1.npz',\n",
    "                    **mvl_2ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvl_2ds['S200'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-001\tses-01\t1\t-9.08446970946553e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-113cfe6f17f0>:9: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  preload=True, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "task = tasks_df.iloc[0]\n",
    "for task in tasks_df.iloc:\n",
    "    if (check_completed(task)):\n",
    "        pass\n",
    "    \n",
    "#     raw = mne.io.read_raw_eeglab(os.path.join(task['dir'], 'pre_' + task['file_formatter'].format('eeg.set')),\n",
    "#                                  preload=True, verbose=0)\n",
    "    raw = mne.io.read_raw_eeglab('/home/kiani/DS/send_to_google_drive/sub-012/ses-01/eeg/pre_sub-012_ses-01_task-Rest_eeg_double.set',\n",
    "                                 preload=True, verbose=0)\n",
    "    print('\\t'.join([f'{task.participant_id}', \n",
    "                     task.dir.split('/')[-2],\n",
    "                     f'{task.pd_drug_type}',\n",
    "                     f'{raw._data[0, 0]}']))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sub-001', 1, 'ses-01', 9.217957080229381e-06)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(task.participant_id, task.pd_drug_type, task.dir.split('/')[-2], raw._data[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "participant_id                                              sub-001\n",
       "pd_drug_type                                                      1\n",
       "isMale                                                         True\n",
       "age                                                              75\n",
       "dir               /home/kiani/DS/ds003490-download/sub-001/ses-0...\n",
       "file              sub-001_ses-01_eeg_sub-001_ses-01_task-Rest_ee...\n",
       "file_formatter                          sub-001_ses-01_task-Rest_{}\n",
       "path              /home/kiani/DS/ds003490-download/sub-001/ses-0...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
